{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# PCA Warmup\n", "hell yeah\n", "\n", "## Concepts\n", "\n", "#### Give at least two reasons why one might use PCA.  Be sure to include discussion of what problem PCA solves and how."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#Your answers here"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# Run as-is\n", "from sklearn.datasets import make_classification\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.decomposition import PCA\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import f1_score\n", "from sklearn.model_selection import cross_validate\n", "from sklearn.preprocessing import StandardScaler\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "\n", "%matplotlib inline\n", "import pickle as pkl\n", "\n", "with open('test_obj/X.pkl', 'rb') as f:\n", "    X = pkl.load(f)\n", "\n", "with open('test_obj/y.pkl', 'rb') as f:\n", "    y = pkl.load(f)  \n", "\n", "from test_scripts.test_class import Test\n", "test = Test()"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>0</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <td>0</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <td>1</td>\n", "      <td>1</td>\n", "    </tr>\n", "    <tr>\n", "      <td>2</td>\n", "      <td>1</td>\n", "    </tr>\n", "    <tr>\n", "      <td>3</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <td>4</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <td>9995</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <td>9996</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <td>9997</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <td>9998</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <td>9999</td>\n", "      <td>1</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>10000 rows \u00d7 1 columns</p>\n", "</div>"], "text/plain": ["      0\n", "0     0\n", "1     1\n", "2     1\n", "3     0\n", "4     0\n", "...  ..\n", "9995  0\n", "9996  0\n", "9997  0\n", "9998  0\n", "9999  1\n", "\n", "[10000 rows x 1 columns]"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["import pandas as pd\n", "\n", "df_x = pd.DataFrame(X)\n", "df_y = pd.DataFrame(y)\n", "\n", "df_y"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Application\n", "\n", "### Data Exploration\n", "\n", "- Turn `X` (a np array of features) into a dataframe.  How many features are there? \n", "\n", "- Turn `y` (a np array of the target) into a df.  What type of data is `y`?\n", "\n", "- What kind of prediction problem is this?  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# your work here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### PCA Exploration\n", "\n", "#### Run the following steps\n", "- TTS, `random_state` = 1\n", "\n", "- Scale w/ StandardScaler\n", "\n", "- For the full PCA transformation (ie, w/o specifying `n_components` number)\n", "on `X_train`, store the explained variance ratio for each component \n", "in `evr`\n", "\n", "- Graph `evr`\n", "\n", "- Re-graph the first few components in order to focus on them (you'll see why)\n", "\n", "How many principal components does it look like we should choose?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#Your work here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Calculate Train and Test Error\n", "\n", "#### Run the following:\n", "- for the first 50 principal components,\n", "  - scale the data\n", "  - generate the number of principal components and transform them into features\n", "  - Using Logistic Regression with default inputs, generate train and test predictions through 10-fold cross validation\n", "    - *Hint:* use `sklearn.cross_validate`\n", "    - *Level up:* ideally, you would scale and PCA on each training fold (why?).  Use a pipeline!\n", "  - graph the means of the train and test predictions for each number of principal component\n", "\n", "#### Interpret the graph  \n", "- How many principle components should we choose based on this?\n", "- Is overfitting or underfitting a problem?\n", "\n", "#### Level up\n", "- Repeat the above but don't scale the data.  Intepret the results."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#Your work here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}